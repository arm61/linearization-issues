% Define document class
\documentclass[journal=jceda8,manuscript=article]{achemso}
\usepackage{showyourwork}
\usepackage[version=4]{mhchem}
\usepackage{graphicx}
\usepackage{siunitx}

% Author list
\author{Andrew R. McCluskey}
\email{andrew.mccluskey@bristol.ac.uk}
\affiliation{School of Chemistry, University of Bristol, Cantock's Close, Bristol, BS8 1TS, United Kingdom}
\altaffiliation{European Spallation Source ERIC, Ole Maaløes vej 3, 2200 København N, Denmark}

% Title
\title{Is there still a place for linearization in the chemistry curriculum?}

% Begin!
\begin{document}

\begin{abstract}
    The use of mathematical transformations to reduce non-linear functions to linear problems, which can be tackled with analytical linear regression, is commonplace in the chemistry curriculum. 
    The linearization procedure, however, assumes an incorrect statistical model for real experimental data; leading to biased estimates of regression parameters and should therefore not be used in formal data analysis. 
    This fact is overlooked in many chemistry degrees, as when linearization is introduced, students do not yet have the mathematical knowledge to appreciate why linearization leads to bias.
    I hope that this commentary will start a discussion in the community around the place of linearization in the chemistry curriculum, and more broadly around how mathematical and statistical training is currently provided to chemistry students. 
\end{abstract}

\noindent\textbf{Keywords}: linearization, maths for chemists, data skills, statistics, mathematics.

\maketitle 

In chemistry, non-linear relationships are commonly found between dependent and independent variables.
These relationships can be simplified by the process of ``linearization'', where some mathematical transformation is used to reduce the non-linear problem to a linear one. 
By linearizing a function, analytical linear regression can be used to quantify parameters of interest, rather than relying on numerical optimisation. 
We see this process in chemistry textbooks~\cite{monk_math_2010,atkins_physical_2018} and undergraduate degree programs: for example where it is applied to first- and second-order rate equations, and the Clausius-Clapeyron and Arrhenius equations~\cite{perrin_linear_2017,monk_math_2010}.

While mathematically sound for noise-free measurements, linearization can introduce errors in the analysis process for real experimental data. 
Specifically, it can lead to biased estimates of regression parameters; the gradient and intercept of the straight line -- as has been noted in this Journal and others~\cite{delevie_when_1986,rusling_minimizing_1988,zielinski_least_1997,denton_analysis_2000,levent_dont_2004,rittenhouse_chapter_2005,perrin_linear_2017,moeglich_open_2018,alamillo_mechanistic_2022}.
Therefore in formal analysis, where accurate and precise estimates of the parameters of interest are desired, the use of linearization should be avoided. 
Despite this, linearization is still included in a general chemistry education, without discussion of the problems caused by it, resulting in a vicious cycle; linearization is taught to students as it appears in the research literature and is then used in the research literature as the practitioners are not aware of the problems. 
The problems of linearization are rarely discussed when introduced, as at this stage students have not been introduced to the mathematical or statistical concepts required to appreciate the sources of the problems or the details of the preferred non-linear optimization.
This author believes that instead of introducing linearization as a data analysis tool, students should receive a more complete training in the relevant data analysis skills and linearization should be kept as a basic visualisation tool.

Although it has been covered by others, it is important to restate the problem that results from linearization.
For this we can consider the decomposition of hydrogen peroxide \ce{H2O2} in the presence of excess cerium(III) ion, which follows first-order rate kinetics with the form~\cite{monk_math_2010}
%
\begin{equation}
    [\ce{H2O2}]_t = [\ce{H2O2}]_0\exp{(-kt)},
    \label{eqn:first}
\end{equation}
%
where, $[\ce{H2O2}]_t$ is the concentration of hydrogen peroxide at time $t$, $[\ce{H2O2}]_0$ is the initial concentration and $k$ is the rate constant (representative data is shown in Figure~\ref{fig:ols}a).
Linearization of Equation~\ref{eqn:first} involves taking the natural logarithm of both sides to produce
%
\begin{equation}
    \ln{[\ce{H2O2}]_t} = -kt + \ln{[\ce{H2O2}]_0}.
    \label{eqn:log}
\end{equation}
%
The gradient and intercept from linear regression, of $\ln{[\ce{H2O2}]_t}$ on $t$, are therefore equal to $-k$ and $\ln{[\ce{H2O2}]_0}$, respectively (Figure~\ref{fig:ols}b).

If we were to perform repeated measurements of the concentration of \ce{H2O2} as a function of reaction time and analyse each repeat, we can build up a distribution of estimates of $k$ (Figure~\ref{fig:ols}c \&~\ref{fig:ols}d). 
The simplest way to analyse a linearized function is by ordinary least squares (OLS) linear regression, which we can compare with unweighted non-linear optimization. 
Non-linear fitting gives a normal distribution of estimated values of $k$, with a mean centred on the true value, i.e. the estimation is unbiased. 
The linearized form, however, gives a biased, broad, asymmetrical distribution, where the normalised mean is \variable{output/lin_mean_ols.txt}.
The linearized approach will, on average, overestimate the value of $k$ and any single estimate of $k$ has a higher chance of being further from the true value. 
%
\begin{figure}
  \includegraphics[width=0.5\columnwidth]{figures/ols.pdf}
  \caption{
    Representative data for first-order integrated rate equation, with a true value of $k=\SI{0.15}{\per\second}$ and $[\ce{A}]_0=\SI{7.5}{\mol\m^{-3}}$, showing (a) the non-linear and (b) the linearized forms. 
    Estimates of $k$, normalised to the true value of $k$, from $2^{15}$ analyses of unique representative datasets, using (c) unweighted non-linear fitting and (d) linearization followed by ordinary least squares, with the vertical lines indicating the distribution means.
    }
  \label{fig:ols}
  \script{ols.py}
\end{figure}
%

By using OLS or unweighted non-linear optimisation, we are assuming that the uncertainties in our data are all the same, i.e., they are homoscedastic. 
It was noted by Perrin~\cite{perrin_linear_2017}, however, these homoscedastic uncertainties may become heteroscedastic as a result of the linearization process (note the error bars in Figure~\ref{fig:wls}b). 
Therefore, the use of OLS for linearized data is insufficient, instead weighted least squares (WLS), where the weights are determined by Gaussian error propagation, should be used.
For the example in Equation~\ref{eqn:log}, the correct error propagation is to divide the measured error by the nominal value (Figure~\ref{fig:wls}b).
WLS leads to a normal distribution of estimated $k$, but still, the distribution is biased (Figure~\ref{fig:wls}d), with a normalised mean of \variable{output/lin_mean_wls.txt}.
Non-linear optimisation, meanwhile, still produces an unbiased estimate.
%
\begin{figure}
  \includegraphics[width=0.5\columnwidth]{figures/wls.pdf}
  \caption{
    The same representative data as Figure~\ref{fig:ols} with error bars of \SI{0.3}{{\mol\m^{-3}}} (a \& b).
    The same number of analyses were performed, however, this time using (c) weighted non-linear optimisation and (d) weighted least squares with propagated uncertainties, the vertical lines indicate the mean of the distribution. 
    }
  \label{fig:wls}
  \script{wls.py}
\end{figure}
%

The observed bias can be understood by recognising that the measurement of any variable, $y$, is only ever an estimate of the true value, $\hat{y}$, which is a random draw from a distribution of values, $p(y)$. 
The shape of this distribution depends on the noise or uncertainty in the measurement. 
It is commonly assumed that random uncertainty sources will lead to a normal distribution, $p(y) \sim \mathcal{N}(\mu, \sigma^2)$, which is defined by the mean, $\mu$, and standard deviation, $\sigma$ (Figure~\ref{fig:distributions})~\cite{monk_math_2010}.
When linearization is used, a mathematical transformation is performed on the dependent variable and if that transformation scales in a non-linear fashion, i.e., the reciprocal or logarithm is taken, it will cause the normally distributed variable to become non-normal (Figures~\ref{fig:distributions}b \&~\ref{fig:distributions}c).
Similarly, the use of Gaussian error propagation, in the WLS case, also breaks down with linearization, as Gaussian error propagation involves the application of a truncated Taylor expansion, in this case, to a non-linear function leading to a large truncation error.
%
\begin{figure}
  \includegraphics[width=0.66 \columnwidth]{figures/distributions.pdf}
  \caption{  
    Histograms showing the effect on (a) a normal distribution, of mathematical transformations that scale non-linearly: (b) the reciprocal or (c) the logarithm. 
    Produced from $2^{15}$ random samples from the normal distribution $\mathcal{N}(50, 10^2)$.
    }
  \label{fig:distributions}
  \script{distributions.py}
\end{figure}
%

For normally distributed variables, both OLS and WLS produce unbiased estimates of the regression parameters. 
However, this is not the case when non-normally distributed variables are used. 
By applying OLS or WLS to non-normally distributed variables, we use the wrong statistical model for our analysis. 
However, the correct statistical model is being applied in the non-linear optimisation case, where the variables have not been transformed and are therefore still normally distributed. 

While there is some role for linearization as a data visualization tool, e.g., the doubling of a reaction rate may be more obvious on a linearized plot, or as a qualitative classroom exercise, it should not be taught as a tool for the analysis of data. 
In addition to improving the mathematical accuracy of analysis performed by students, this will help to break down the vicious cycle that results in potentially erroneous results appearing in the research literature.
Furthermore, there are additional learning outcomes in showing students that the way that data is represented graphically may skew their interpretation.
Specifically, this can be achieved by comparing the linearized and non-linear optimized solutions on the linearized and non-linear plots. 

This author hopes that this commentary will both remind readers of the problems associated with linearization and inspire discussion in the community regarding how and when mathematical and statistical skills are taught to students. 
In my experience (which admittedly has been focused on the United Kingdom), students are rarely introduced to much statistical methodology, beyond the basics of summary statistics and Gaussian error propagation, before they are tasked with data analysis problems, e.g., students are asked to produce ``lines of best fit'' without being introduced to ordinary least squares.
Therefore, to ensure that students appreciate why linearization is problematic, among many other benefits, they should be given a more complete training in the mathematical and statistical underpinnings of data analysis before linearization is introduced.

The importance of ``data skills'' in a chemical education is underestimated and should be considered similar to that of traditional mathematical concepts, such as calculus, which underpin theoretical aspects of the chemical sciences.
Data skills, including handling, analysis and basic programming skills, make chemists more capable in future research projects, more employable both inside and outside of the chemical industry, and can aid in the understanding of complex subjects~\cite{srnec_python_2017,chng_building_2020,dicksonkarn_implementation_2021,cumby_course_2023}.
Without facilitating this component of a chemist's education, we are failing to equip them to approach modern problems that they will find in the chemical sciences. 

\section*{Data availability}

Electronic Supplementary Information (ESI) available: A complete set of analysis/plotting scripts allowing for a fully reproducible and automated analysis workflow, using showyourwork~\cite{luger_showyourwork_2021}, for this work and a Jupyter Notebook showing the use of weighted non-linear optimisation for representative first-order rate kinetics data is available at \url{https://github.com/arm61/linearization-issues} (DOI: 10.5281/zenodo.7949905) under an MIT license, while the text is shared under a CC BY-SA 4.0 license~\cite{mccluskey_github_2023}.

\section*{Acknowledgements}

The author thanks Benjamin J. Morgan, Samuel W. Coles, Thomas Holm Rod, Gabriel Krenzer, and Kasper Tolborg for the insightful discussion that led to this work. 
Additionally, the author would like to thank those that engaged in discussion on Twitter, in particular Carl Poree and Fiona Dickinson, when the problem of linearization in Arrhenius modelling was initially raised. 

\bibliography{bib}

\end{document}
